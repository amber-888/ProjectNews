{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  数据重复会导致数据的方差变小，数据分布发生较大变化。缺失会导致样本信息减少，不仅增加了数据分析的难度，而且会导致数据分析的结果产生偏差。异常值则会产生“伪回归”。因此需要对数据进行检测，查询是否有重复值、缺失值和异常值，并且要对这些数据进行适当的处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.检测与处理重复值\n",
    "\n",
    "### 1.1记录重复值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  菜品订单详情表中的dishes_name特征存放了每个订单的菜品。要找出所有已点菜品，最简单的方法就是利用去重操作实现。\n",
    "\n",
    "#### 方法一：利用list 列表去重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  代码5-9 利用list 列表去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前菜品总数为： 10037\n",
      "方法一去重后菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "detail = pd.read_csv('./data/detail.csv',\n",
    "    index_col=0,encoding = 'gbk')\n",
    "\n",
    "##方法一\n",
    "##定义去重函数\n",
    "def delRep(list1):\n",
    "    list2=[]\n",
    "    for i in list1:\n",
    "        if i not in list2:\n",
    "            list2.append(i)\n",
    "    return list2 \n",
    "## 去重\n",
    "dishes=list(detail['dishes_name']) ##将dishes_name从数据框中提取出来\n",
    "print('去重前菜品总数为：',len(dishes)) \n",
    "dish = delRep(dishes) ##使用自定义的去重函数去重\n",
    "print('方法一去重后菜品总数为：',len(dish))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法二：利用set集合去重。\n",
    "\n",
    "####  代码5-10 利用set集合去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重前菜品总数为： 10037\n",
      "方法二去重后菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "print('去重前菜品总数为：',len(dishes)) \n",
    "dish_set = set(dishes) ##利用set的特性去重\n",
    "print('方法二去重后菜品总数为：',len(dish_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  比较上述两种方法可以发现，代码5-9中的方法明显代码冗长，会拖慢数据分析的整体进度。                                                                                     代码5-10 使用了集合的元素的唯一性，看似代码简洁多了。但这种方法的最大问题是会导致数据的排列发生变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas提供了一个名为drop_duplicates的去重方法。该方法只对DataFrame或者Series类型有效。这种方法不会改变数据原始排列，并且代码简洁和运行稳定。                                                                                                                                               \n",
    "### pandas.DataFrame(Series).drop_drop_duplicates(self,subset=None,keep='first',inplace=False)\n",
    "\n",
    "###  使用该方法去重时，当且仅当subset参数中的特征重复的时候才会执行去重操作，去重时可以选择保留哪一个，甚至可以不保留。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  代码5-11利用drop_duplicates方法对菜品名称去重（菜品订单详情表）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_duplicates方法去重之后菜品总数为： 145\n"
     ]
    }
   ],
   "source": [
    "##对dishes_name去重\n",
    "dishes_name = detail['dishes_name'].drop_duplicates()\n",
    "print('drop_duplicates方法去重之后菜品总数为：',len(dishes_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  代码5-12利用drop_duplicates方法对多列去重（菜品订单详情表）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重之前订单详情表的形状为： (10037, 18)\n",
      "依照订单编号，会员编号去重之后订单详情表大小为: (942, 18)\n"
     ]
    }
   ],
   "source": [
    "print('去重之前订单详情表的形状为：', detail.shape)\n",
    "shapeDet = detail.drop_duplicates(subset = ['order_id',\n",
    "    'emp_id']).shape\n",
    "print('依照订单编号，会员编号去重之后订单详情表大小为:', shapeDet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.2 特征重复\n",
    "\n",
    "#### 结合相关的数学和统计学知识，去除连续型特征重复可以利用特征间的相似度将两个相似度为1的特征去除一个。在pandas中相似度的计算方法为corr，使用该方法计算相似度时，默认为“pearson”法 ，可以通过“method”参数调节，目前还支持“spearman”法和“kendall”法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  代码5-13 使用kendall法求出菜品订单详情表(detail.csv)数据中counts和amounts列的相似度矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销量和售价的kendall相似度为：\n",
      "            counts   amounts\n",
      "counts   1.000000 -0.229968\n",
      "amounts -0.229968  1.000000\n"
     ]
    }
   ],
   "source": [
    "## 求取销量和售价的相似度\n",
    "corrDet = detail[['counts','amounts']].corr(method='kendall')\n",
    "print('销量和售价的kendall相似度为：\\n',corrDet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 但是通过相似度矩阵去重存在一个弊端，该方法只能对数值型重复特征去重，类别型特征之间无法通过计算相似系数来衡量相似度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  对订单详情表(detail.csv)中'dishes_name','counts', 'amounts' 这3个特征进行  “pearson”法 相似度矩阵的求解，但是最终只存在'counts'和'amounts'特征的2*2的相似度矩阵\n",
    "\n",
    "####  代码5-14 'dishes_name','counts', 'amounts' 这3个特征进行  “pearson”法 相似度矩阵的求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "菜品名称，销量和售价的pearson相似度为：\n",
      "            counts   amounts\n",
      "counts   1.000000 -0.159264\n",
      "amounts -0.159264  1.000000\n"
     ]
    }
   ],
   "source": [
    "corrDet1 = detail[['dishes_name','counts',\n",
    "    'amounts']].corr(method='pearson')\n",
    "print('菜品名称，销量和售价的pearson相似度为：\\n',corrDet1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 除了使用相似度矩阵进行特征去重之外，可以通过DataFrame.equals的方法进行特征去重。\n",
    "\n",
    "####  代码5-15 使用过DataFrame.equals的方法进行特征去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail的特征相等矩阵的前5行5列为：\n",
      "                    order_id  dishes_id  logicprn_name  parent_class_name  \\\n",
      "order_id               True      False          False              False   \n",
      "dishes_id             False       True          False              False   \n",
      "logicprn_name         False      False           True               True   \n",
      "parent_class_name     False      False           True               True   \n",
      "dishes_name           False      False          False              False   \n",
      "\n",
      "                   dishes_name  \n",
      "order_id                 False  \n",
      "dishes_id                False  \n",
      "logicprn_name            False  \n",
      "parent_class_name        False  \n",
      "dishes_name               True  \n"
     ]
    }
   ],
   "source": [
    "##定义求取特征是否完全相同的矩阵的函数\n",
    "def FeatureEquals(df):\n",
    "    dfEquals=pd.DataFrame([],columns=df.columns,index=df.columns)\n",
    "    for i in df.columns:\n",
    "       for j in df.columns:\n",
    "           dfEquals.loc[i,j]=df.loc[:,i].equals(df.loc[:,j])\n",
    "    return dfEquals\n",
    "## 应用上述函数\n",
    "detEquals=FeatureEquals(detail)\n",
    "print('detail的特征相等矩阵的前5行5列为：\\n',detEquals.iloc[:5,:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  再通过遍历的方式筛出完全重复的特征。\n",
    "\n",
    "####  代码5-16 通过遍历的方式进行数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要删除的列为： ['parent_class_name', 'cost', 'discount_amt', 'discount_reason', 'kick_back', 'add_info', 'bar_code', 'add_inprice']\n",
      "删除多余列后detail的特征数目为： 10\n"
     ]
    }
   ],
   "source": [
    "##遍历所有数据\n",
    "lenDet = detEquals.shape[0]\n",
    "dupCol = []\n",
    "for k in range(lenDet):\n",
    "    for l in range(k+1,lenDet):\n",
    "        if detEquals.iloc[k,l] & (detEquals.columns[l] not in dupCol):\n",
    "            dupCol.append(detEquals.columns[l])\n",
    "##进行去重操作\n",
    "print('需要删除的列为：',dupCol)\n",
    "detail.drop(dupCol,axis=1,inplace=True)\n",
    "print('删除多余列后detail的特征数目为：',detail.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.检测与处理缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据中的某个或某些特征的值是不完整的，这些值称为缺失值。\n",
    "#### pandas提供了识别缺失值的方法isnull以及识别非缺失值的方法notnull，这两种方法在使用时返回的都是布尔值True和False。\n",
    "#### 结合sum函数和isnull、notnull函数，可以检测数据中缺失值的分布以及数据中一共含有多少缺失值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码5-17 isnull和notnull用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail每个特征缺失的数目为：\n",
      " order_id                0\n",
      "dishes_id               0\n",
      "logicprn_name       10037\n",
      "dishes_name             0\n",
      "itemis_add              0\n",
      "counts                  0\n",
      "amounts                 0\n",
      "place_order_time        0\n",
      "picture_file            0\n",
      "emp_id                  0\n",
      "dtype: int64\n",
      "detail每个特征非缺失的数目为：\n",
      " order_id            10037\n",
      "dishes_id           10037\n",
      "logicprn_name           0\n",
      "dishes_name         10037\n",
      "itemis_add          10037\n",
      "counts              10037\n",
      "amounts             10037\n",
      "place_order_time    10037\n",
      "picture_file        10037\n",
      "emp_id              10037\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('detail每个特征缺失的数目为：\\n',detail.isnull().sum())\n",
    "print('detail每个特征非缺失的数目为：\\n',detail.notnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### isnull和notnull之间结果正好相反，因此使用其中任意一个都可以判断出数据中缺失值的位置。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   2.1 删除法\n",
    "\n",
    "#### 删除法分为删除观测记录和删除特征两种，它属于利用减少样本量来换取信息完整度的一种方法，是一种最简单的缺失值处理方法。\n",
    "#### pandas中提供了简便的删除缺失值的方法dropna，该方法既可以删除观测记录，亦可以删除特征。\n",
    "#### pandas.DataFrame.dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "\n",
    "#### 代码5-18 对菜品订单详情表利用dropna方法删除缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去除缺失的列前detail的形状为： (10037, 10)\n",
      "去除缺失的列后detail的形状为： (10037, 9)\n"
     ]
    }
   ],
   "source": [
    "print('去除缺失的列前detail的形状为：', detail.shape)\n",
    "print('去除缺失的列后detail的形状为：',\n",
    "    detail.dropna(axis = 1,how ='any').shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 当how参数取值为any时，删除了一个特征，说明这个特征存在缺失值。若how参数不取any这个默认值，而是取all，则表示整个特征全部为缺失值时才会执行删除操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   2.2替换法\n",
    "\n",
    "#### 替换法是指用一个特定的值替换缺失值。\n",
    "#### 特征可分为数值型和类别型，两者出现缺失值时的处理方法也是不同的。\n",
    "#### 缺失值所在特征为数值型时，通常利用其均值、中位数和众数等描述其集中趋势的统计量来代替缺失值。\n",
    "#### 缺失值所在特征为类别型时，则选择使用众数来替换缺失值。\n",
    "\n",
    "#### 代码5-19使用fillna方法替换缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail每个特征缺失的数目为：\n",
      " order_id            0\n",
      "dishes_id           0\n",
      "logicprn_name       0\n",
      "dishes_name         0\n",
      "itemis_add          0\n",
      "counts              0\n",
      "amounts             0\n",
      "place_order_time    0\n",
      "picture_file        0\n",
      "emp_id              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "detail = detail.fillna(-99)\n",
    "print('detail每个特征缺失的数目为：\\n',detail.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   2.3 插值法\n",
    "\n",
    "\n",
    "#### 代码5-20 SCIPy interpolate模块插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为6、7时，使用线性插值y1为： [ 76. 102.]\n",
      "当x为6、7时，使用线性插值y2为： [13. 15.]\n"
     ]
    }
   ],
   "source": [
    "## 线性插值\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "x=np.array([1,2,3,4,5,8,9,10]) ##创建自变量x\n",
    "y1=np.array([2,8,18,32,50,128,162,200]) ##创建因变量y1\n",
    "y2=np.array([3,5,7,9,11,17,19,21]) ##创建因变量y2\n",
    "LinearInsValue1 = interp1d(x,y1,kind='linear') ##线性插值拟合x,y1\n",
    "LinearInsValue2 = interp1d(x,y2,kind='linear') ##线性插值拟合x,y2\n",
    "print('当x为6、7时，使用线性插值y1为：',LinearInsValue1([6,7]))\n",
    "print('当x为6、7时，使用线性插值y2为：',LinearInsValue2([6,7]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为6,7时，使用拉格朗日插值y1为： [72. 98.]\n",
      "当x为6,7时，使用拉格朗日插值y2为： [13. 15.]\n"
     ]
    }
   ],
   "source": [
    "## 拉格朗日插值\n",
    "from scipy.interpolate import lagrange\n",
    "LargeInsValue1 = lagrange(x,y1) ##拉格朗日插值拟合x,y1\n",
    "LargeInsValue2 = lagrange(x,y2) ##拉格朗日插值拟合x,y2\n",
    "print('当x为6,7时，使用拉格朗日插值y1为：',LargeInsValue1([6,7]))\n",
    "print('当x为6,7时，使用拉格朗日插值y2为：',LargeInsValue2([6,7]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为6,7时，使用样条插值y1为： [72. 98.]\n",
      "当x为6,7时，使用样条插值y2为： [13. 15.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: `spline` is deprecated!\n",
      "spline is deprecated in scipy 0.19.0, use Bspline class instead.\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: `spline` is deprecated!\n",
      "spline is deprecated in scipy 0.19.0, use Bspline class instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "##样条插值\n",
    "from scipy.interpolate import spline\n",
    "##样条插值拟合x,y1\n",
    "SplineInsValue1 = spline(x,y1,xnew=np.array([6,7]))\n",
    "##样条插值拟合x,y2\n",
    "SplineInsValue2 = spline(x,y2,xnew=np.array([6,7]))\n",
    "print('当x为6,7时，使用样条插值y1为：',SplineInsValue1)\n",
    "print('当x为6,7时，使用样条插值y2为：',SplineInsValue2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.检测与处理异常值\n",
    "\n",
    "###   3.1  3σ原则\n",
    "\n",
    "####  代码 5-21 使用3σ原则识别异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用拉依达准则判定异常值个数为: 209\n",
      "异常值的最大值为： 10\n",
      "异常值的最小值为： 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## 定义拉依达准则识别异常值函数\n",
    "def outRange(Ser1):\n",
    "    boolInd = (Ser1.mean()-3*Ser1.std()>Ser1) | \\\n",
    "    (Ser1.mean()+3*Ser1.var()< Ser1)\n",
    "    index = np.arange(Ser1.shape[0])[boolInd]\n",
    "    outrange = Ser1.iloc[index]\n",
    "    return outrange\n",
    "outlier = outRange(detail['counts'])\n",
    "print('使用拉依达准则判定异常值个数为:',outlier.shape[0])\n",
    "print('异常值的最大值为：',outlier.max())\n",
    "print('异常值的最小值为：',outlier.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3σ原则具有一定的局限性，即此原则只对正态分布或近似正态分布的数据有效，而对其分布类型的数据无效"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   3.2.箱线图分析\n",
    "\n",
    "####  代码 5-22菜品售价根据箱线图识别异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售量数据异常值个数为： 516\n",
      "销售量数据异常值的最大值为： 10\n",
      "销售量数据异常值的最小值为： 2\n"
     ]
    }
   ],
   "source": [
    "# 代码 5-22\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,8)) \n",
    "p = plt.boxplot(detail['counts'].values,notch=True)   ##画出箱线图\n",
    "outlier1 = p['fliers'][0].get_ydata()   ##fliers为异常值的标签\n",
    "plt.savefig('../tmp/菜品异常数据识别.png')\n",
    "plt.show()\n",
    "print('销售量数据异常值个数为：',len(outlier1))\n",
    "print('销售量数据异常值的最大值为：',max(outlier1))\n",
    "print('销售量数据异常值的最小值为：',min(outlier1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  可以从结果中看出，菜品订单表中的菜品售价存在着为数不少的异常值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
